name: number-crunching
files:
  evaluation-results: experiments/number-crunching/evaluation-results.yaml
  model: &model experiments/number-crunching/number-crunching.sp
  new-rules: &new-rules experiments/number-crunching/new-rules.yaml
  scenario: real_world_problems/number_crunching/dataset.yaml
  solver-trainings-data: &solver-data experiments/number-crunching/solver-trainings-data.bin
  training-statistics: &training-statistics experiments/number-crunching/training-statistics.yaml
  trainings-data-traces: experiments/number-crunching/trace_*.tr
  trainings-data: &bag experiments/number-crunching/number-crunching.bin
  working-folder: experiments
  t3-loop-traces: experiments/number-crunching/t3-loop-results.spb
generation:
  stages: []
  max-depth: 8
  max-size: 7
  min-working-density: 0.1
  min-result-density: 0.05
  distribution-suppression-exponent: 1.8
  augmentation:
    enabled: false # Not relevant here
    factor: 10
  blacklist-pattern: []
training:
  save-model: *model
  device: cpu
  # Learning
  num-epochs: 500
  report-rate: 10
  batch-size: 8
  learning-rate: 0.1
  gradient-clipping: 0.1
  value-loss-weight: 0.5
  model-name: TreeCnnSegmenter
  # Scenario
  scenario: bag
  filename: *bag
  solver-filename: *solver-data
  statistics: *training-statistics
  data-size-limit: -1
  model-parameter:
    embedding_size: 64
    hidden_layers: 2
    dropout: 0
    use_props: True
    residual: False
evaluation:
  num-epochs: 30
  problems:
    beam-size: 10
    num_epochs: 10
    max_track_loss: 3 # abort if the value is bad for longer
    max_fit_results: 1000
    iterations: 5
  trainings-data:
    beam-size: "1:15"
    max-steps: -1
  solver-trainings-data: *solver-data
  new-rules-filename: *new-rules
  # blacklists
  max-size: 7
  black-list-terms: []
  black-list-rules: []
