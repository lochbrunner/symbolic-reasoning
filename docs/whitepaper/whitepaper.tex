\documentclass{scrartcl}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{babel}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage[dvipsnames]{xcolor}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{import}
\usepackage{subfigure}

\subimport{docs/libs/}{init}

\usetikzlibrary{patterns}
\usetikzlibrary{positioning}

\usepackage[
backend=biber,
% style=alphabetic,
sorting=none
]{biblatex}

\addbibresource{whitepaper.bib}

\title{Rule based Symbolic Reasoning}
\author{Matthias Lochbrunner}
\date{\today}

\theoremstyle{definition}
\newtheorem{exmp}{Example}[section]

\pgfplotsset{colormap/jet}

\tikzset{
    fromColorBar/.style={
        color of colormap={1000-#1*10},
        fill=.,
    },
}

\begin{document}
\maketitle
\begin{center}
	\textbf{Abstract}
\end{center}
\begin{abstract}
	The combination of a rule based beam search and deep learning is a promising approach to solve mathematical problems.
	One obstacle to overcome is the amount of possible branches in this search as the number of applicable rules and length of the calculation increases.
	This paper proposes to address this issue by constantly shrinking the beam size with a multi-head neuronal network:
	A policy head selects rules and positions in the current term.
	A value head evaluates the probability that this calculation could lead to the desired solution.
	Both heads help to reduce the beam size such that solving advanced mathematical problems becomes feasible.
\end{abstract}

\section{Motivation}

Since current approaches to solve mathematical problems use a complex but fixed set of rules, it takes manual effort to extend their capabilities \cite{wolfram}.
The generic approach described here might be able to incorporate additional rules without requiring manual work.
Moreover, it is not limited to mathematical problems as long as the domain can be described by a well-defined rule set.
The correctness of the result depends only on the correctness of the given rule set.

Gary Marcus proposes a hybrid, knowledge-driven, reasoning-based approach, centered around cognitive models,
that could provide the substrate for a richer, more robust AI than is currently possible. \cite{marcus2020decade}
This paper demonstrates one possible approach.

\section{Related work}

Lampe et. al. use state of the art sequence to sequence transformers (Vaswani et al. \cite{vaswani2017attention}) on equations formatted in the polish notation  \cite{Lample2020Deep}.
This approach views solving a mathematical problem as a translation problem.
% They don't use the concept of rules and tree structured data in the network.
Davis reviewed this work and come to the conclusion, that is astonishing that their transformer model outperforms contemporary computer algebra systems.
But he criticizes the limited vocabulary used in their generated data set \cite{davis2019use}.
In their latest paper they widened the scope of to five advanced mathematical problems and improved the many of the limitations discussed by the community \cite{charton2021learning}.
Inspired on that work Hahn et. al. also use a transformer based network for linear-time temporal logical formulas (LTL) \cite{hahn2021teaching}.
Similar to the result of the work by Lampe their method is capable to solve large formulas, but some results are semantically and syntactically wrong.

Lamb et al. presented a review on the relationship between GraphNeural Network (GNN) models and architectures and Neural-Symbolic Computing (NSC) \cite{lamb2020graph}.
They pointed out that this combination could provide trustful, explainable and robust AI systems.

Panju et at. build up a novel symbolic function learner to solve differential equations \cite{panju2020neurosymbolic}.
Their modeling approach is to iteratively feed the individual nodes of a syntax tree from the leaves to the root.
A very similar approach elaborated by Piepenbrock et al. \cite{piepenbrock2021learning}. 
% This method is able to approximate a symbolic function when the problem has no elementary symbolic solution.

A significant improvement is worked out by Rabe et al. They use an unsupervised proxy task to pre-train a sequence to sequence language model \cite{rabe2020mathematical}.
In their skip-tree training task the model is trained to predict a subtree in the syntax tree of an expression.
It is remarkable that they consider typed inference for variables and propositional logic to some extent.


\section{Method}

Given a problem, e.g. solve the equation $T_1\left(x\right)\equiv T_2\left(x\right)$ for $x$,
the beam search could try to apply various rules at different nodes in the syntax tree of the equation.
The policy head proposes the most promising combination of rules $R_j$ and positions $p_\ell$ in the current equation.
The value head evaluates the probability of success of the current calculation step.
The cumulative result of the value head can abort the solution path of the attempt, as it "seems" unlikely that the this attempt could succeed \cite{44806}.

\subsection{Rule Application}

A rule $R$ consists of one or multiple premises and one conclusion $B$.
In this paper we assume each rule to have only one premise $A$.
The outlook section discusses approaches rule of multiple premisses. 
Every rule is then of the shape $A \Longrightarrow B$ or $A \equiv B$, which is equivalent to $A \Longleftrightarrow B$ or just the combination of $A \Longrightarrow B$ and $B \Longrightarrow A$.
Without loss of correctness we just use the first shape $A \Longrightarrow B$ in this paper.
Let's name the term $T$ with the depth $d$ of the corresponding syntax tree representation.

\begin{figure}[!htbp]
	\centering
	\input{docs/whitepaper/syntax_tree.tex}
	\label{fig:sxntax_tree}
\end{figure}

As the term $T$ can be represented by a tree we will name it's child terms $T_p$ with the position $p \in \big\{\left( n_1, n_2, \dots, n_d \right) | n_i \in \mathbb{N}, n_i \leq s \big\}$.
Hence the sub-terms of $T$ are $T_p$.
For instance $T_1$ is the sub-term at the first child node of the root node in that tree and $T_{1,1}$ is the first child term of $T_1$ and so on.
The root symbol of $T_p$ should be $t_p$.
Figure \ref{fig:sxntax_tree} demonstrates this notation by an example term.
Let $s$ be the maximal number of children per node in the syntax tree.

We try to match the premise term $A_j$ of rule $R_j$ at any position $p$ in term $T$.
Doing so results in a set of possible positions $p_\ell$ with the required substitution table ${M_{j,\ell}: S_{A_j} \to S_{T_{p_\ell}}}$,
where $S_{T_{p_\ell}}$ is the set of the sub-terms in term $T_{p_\ell}$ and $S_{A_j}$ the set of free symbols in the premise $A$.
Free symbols are symbols not defined elsewhere such as standard operators or the number $\pi$.
Then the application of that rule results in the new terms $T^{(j,\ell)}$ where each sub-term at $p_\ell$ gets replaced by the substituted conclusion ${B_j'^{(\ell)} \coloneqq M_{j,\ell}\left( B_j \right)}$.
Where $B_j'^{(\ell)}$ is $B_j$ with symbols mapped back by $M_{j,\ell}$. 

\begin{exmp}
To illustrate the above, let's look at the application of the derivative rule for polynomials.

Consider the derivative rule
\begin{align}
	\frac{\partial}{\partial {\color{red}x}} {\color{red}x}^{\color{blue}n} \Longrightarrow {\color{blue}n}\cdot {\color{red}x}^{{\color{blue}n}-1} 
\end{align}
with the premise $A\equiv \frac{\partial}{\partial {\color{red}x}} {\color{red}x}^{\color{blue}n}$ and the conclusion $B\equiv {\color{blue}n}\cdot {\color{red}x}^{{\color{blue}n}-1}$.
This rule can be applied to a sub-term of
\begin{align}
	a = \frac{\partial}{\partial {\color{red}z}} {\color{red}z}^{\color{blue}4} + b
	\label{example:problem}
\end{align}
at position $p=\left(2,1\right)$ where the derivative $\frac{\partial}{\partial {\color{red}z}} {\color{red}z}^{\color{blue}4}$ is located.
Using the symbol mapping $M\left({\color{red}x}\right) = \color{red}z$ and $M\left({\color{blue}n} \right) = {\color{blue}4}$ leads to the substituted conclusion
$B' = M(B) = M({\color{blue}n}\cdot {\color{red}x}^{{\color{blue}n}-1}) = {M(\color{blue}n})\cdot M({\color{red}x})^{M({\color{blue}n})-1} = {\color{blue}4}\cdot {\color{red}z}^{{\color{blue}4}-1}$.
Now you can replace the sub-term of equation (\ref{example:problem}) at position $p$ with with that $B'$ and obtain the resulting new term
\begin{align}
	a = {\color{blue}4}\cdot {\color{red}z}^{{\color{blue}4}-1} + b
\end{align}.

\end{exmp}

\subsection{Indexed Convolution for Tree Structured Data}

Lampe et. al. showed an approach where they unroll the term $T$ using the polish notation.
Then they apply contemporary NLP translation methods on that sequence where the resulting "translated sentence" is the next step in the calculation \cite{Lample2020Deep}.
The approach discussed here keeps the tree structure.
It turned out that a Tree-LSTM network performs poorly on that data \cite{tai2015improved}.

This paper will discuss the adoption of a network architectures using indexed convolution.
An attention based network with special positional encoding is discussed in the outlook. 

The indexed CNN operation performs a convolution of each node, with their it's neighbor nodes and itself.
Figure \ref{fig:index_tensor} demonstrates the operation by a simple example.

\begin{figure}[!htbp]
	\centering
	\input{docs/whitepaper/index_tensor.tex}
	\label{fig:index_tensor}
\end{figure}

In order to increase the compute efficiency, each term is unrolled.
Let $t_p$ be the symbol at the root of sub-term $T_p$,
then the breadth-first unrolled term with $s=2$ is the vector $\left( t, t_1, t_2, t_{1,1},t_{1,2}, t_{2,1}, t_{2,2}, \cdots \right) \equiv  \left( t_{p_1}, t_{p_2}, t_{p_3},\cdots, t_{p_L} \right)$ of length $L$.
Hence in index notation $t_{p_\ell}$ where $1 \leq \ell \leq L$ is the index of symbol $t_p$ in the unrolled term.
An index map $g \in \mathbb{N}^{L\times \left(K\right)}$ carries the indices of the neighbors in a fixed order.
The kernel $K= s+2$ depends on the spread.
The index map of example in figure \ref{fig:index_tensor} would look like

\begin{align}
	g_{\ell,k} = 
	\begin{pmatrix}
		1 & 2 & 3 & 4 & 5 & 6 & 7 \\
		2 & 4 & 6 & 0 & 0 & 0 & 0 \\
		3 & 5 & 7 & 0 & 0 & 0 & 0 \\
		0 & 1 & 1 & 2 & 2 & 3 & 3 \\
	\end{pmatrix}^\top
\end{align}

where index $0$ points to the padding.


\begin{figure}[!htbp]
	\centering
	\input{docs/whitepaper/iconv.tex}
	\caption{While $x\in \mathbb{R}^{L\times E}$ is the input tensor with $E$ encoded features per symbol $t_\ell$, the network needs the index tensor $g$ is an additional input.
		Each indexed convolution operations (iconv) reads from that index tensor.
		The policy head returns a matrix with the axis rule id $j$ and path id $\ell$. 
		The output of the value head is one scalar per sample in the mini-batch. 
	}
	\label{fig:iconv_network}
\end{figure}

Convolving over the input $x \in \mathbb{R}^{L\times I}$ with indexed convolution $C$ of with input channel $i \in \left[1,\cdots,I\right]$,
the kernel weights $w \in \mathbb{R}^{\left( s+2 \right)\times I \times J}$, output channel $j \in \left[1,\cdots,J\right]$ and bias $b \in \mathbb{R}^J$,
is defined as

\begin{align}
	C\left( x, g, w, b \right)_{\ell j} \coloneqq \sum_{ki}x_{g_{\ell k}i} w_{kij}+b_j
\end{align}

Figure \ref{fig:iconv_network} shows a overview of the multi-head network architecture, where the index tensor $g$ gets distributed to each indexed convolution layer.
These layers are used in the backbone and in the heads.
Due to the padding and stride of one the indexed convolution retains the shape of the input tensor, except of the configurable channel size.
This operation therefore is appropriate for stacking it to deep networks.
A deeper network leads to a larger receptive field and considers more distant symbols.

This is useful for the policy head, which assigns each sub-term a possibility estimation of the most promising rules to apply.

\begin{figure}[!htbp]
	\centering
	\input{docs/whitepaper/network_output.tex}
	\caption{Policy Network output: Each row is a possible rule $R_j$. Each column a sub-term $T_{p_\ell}$ of the initial term $T$ (highlighted in blue font).
	Rules which are not applicable to any $T_{p_\ell}$ are not shown here.
	}
	\label{fig:network_output}
\end{figure}

Figure \ref{fig:network_output} demonstrates the output of the policy head applied on the term $\frac{b}{x}=1\cdot a$.
% Find better example
This heat-map shows that dividing the equation by $a$ is more promising than blowing it up with the rules in in the in the at the bottom of the map.
The value head estimates the probability that the input term can lead to a solution.

\subsection{Three-T-Loop}

The training set consists of problems generated with computer algebra system Sympy \cite{10.7717/peerj-cs.103}.
A training sample is of a rule like shape $T^{(\text I)} \Longrightarrow T^{(\text T)}$ where $T^{(\text I)}$ is the initial problem term and $T^{(\text T)}$ the solution or target term.
The goal is to find the shortest chain of rule applications from the initial term to the target term:

\begin{align}
	T^{(\text I)} \Longrightarrow T^{(j_1)} \Longrightarrow T^{(j_1j_2)} \Longrightarrow \cdots \Longrightarrow T^{(\text T)}
	\label{eq:calculation_chain}
\end{align}

To obtain trainable data from the given problem set, we use an initial beam search without the assistance of a network.
A few simple problems can already be solved by this and learnable data can be extracted from these solution paths.
% Let's call this procedure \textit{three-T-loop} which consists of these three steps:
In order to solve more complex problems we choose an iterative approach.
The data loop consists of three steps:

% how is the network output used

\begin{enumerate}[label=(\roman*)]
	\item \textbf{Try} to solve some of the training problems.
	\item \textbf{Trace} the calculation steps of the solved problems and create training data out of them. 
	\item \textbf{Train} the model with the trainings data from the previous step.
\end{enumerate}
In each iteration of this \textit{three-T-loop}, the number of trainable data increases.
As the network's performance increases, it can solve more and more problems.
The trained network also reduces the number of misleading rule applications.
The value head helps to decide whether the calculation path seems promising to achieve a suitable result.
If the accumulated values are below a threshold the current path gets aborted to save resources (see Figure \ref{fig:beam_search} on page \pageref{fig:beam_search}). 

In order to get the model not doing the same mistake over and over again, it is important to train it with samples of paths which did not lead to a solution. 
These negative samples are present in the training set for value and policy head.


This loop can be extended by a forth step discussed in the outlook section, which allows to incorporate useful sub chains of formula (\ref{eq:calculation_chain}) into the rule set.

\begin{figure}[!htbp]
	\centering
	\input{docs/whitepaper/beam_search.tex}
	\caption{Search beam: The green trace is the correct solution.
	The red branches do not lead to a solution.
	The light nodes are skipped in later searches when the model is trained.}
	\label{fig:beam_search}
\end{figure}


\section{Results}

Todo.
% We have defined a basic rule set to perform the given problems via a scenario configuration.

\begin{figure}[!htbp]
	\centering
	Todo
	\caption{The number of solved problems is increasing as often the T3 loop is iterated.}
	\label{fig:t3loop_performance}
\end{figure}

Figure \ref{fig:t3loop_performance} on page \pageref{fig:t3loop_performance} shows the amount of solved problems over iteration in the \textit{three-T-loop}. 
It turned out that it is very important to suppress nonsensical rule applications, as they can blow up the beam.
To overcome this issue, adding negative training samples is very important.

Although the approach described here for solving mathematical problems is hardly optimized yet,
it has shown that it is capable of solving problems from the field of mathematics.
% Many extension of that approach are possible, as mentioned the "Outlook" section.


\section{Outlook}

Let us group some ideas for extending this approach into two categories:
Due to the limited time budget, many of them could not be tried out yet.
But as the basic algorithm is set up and proven to work, applications based on it's features may be feasible to accomplish in the near future.
The second group would require an extension of this core algorithm, which would take some time to implement.

\subsection{Near Future}

\subsubsection{Transformer and Positional Encoding}

Positional encoding $PE\left( pos\right)$ in NLP is used to "attach" the position $pos$ of a word in the sentence to the embedding of that word \cite{vaswani2017attention}.
The desired properties for the positional encoding $PE\left( T_a \right) - PE\left( T_b \right)$ sub-terms $T_a$ and $T_b$ should be:
\begin{enumerate}[label=(\roman*)]
	\item A metric for the relative distance between sub-terms $T_A$ and $T_B$.
	\item Independent of the absolute position of the sub-terms.
\end{enumerate}

A naive approach is to draw the tree on a two dimensional plane and count the sub-terms from left to right.
This approach does not fullfil any of the desired properties.

But dividing these numbers iteratively by the spread $s$.

\begin{align}
	PE^{(n+1)}\left( T \right) \coloneqq \lfloor \frac{PE^{(n)} \left( T \right)}{s} \rfloor
\end{align}

the collection of $PE^{(n+1)}\left( T \right)$ together with a vertical encoding partly fulfills these properties.
Figure \ref{fig:positional_encoding} demonstrates this procedure by an example.
This could be good enough as input for sine and cosine functions or learnable embeddings \cite{gehring2017convolutional}.

\begin{figure}[!htbp]
	\centering
	\input{docs/whitepaper/positional_encoding.tex}
	\label{fig:positional_encoding}
\end{figure}


\subsubsection{Bellman equation}

%Hint: Using Bellman equation?

\subsubsection{Append Corollaries to the Rule Set}

The basic rule set contains only fundamental definitions that lead to very small steps in the calculation.
These atomic steps can result in long calculation chains seen in formula (\ref{eq:calculation_chain}).

\begin{equation}
	\label{eq:tedios_calculation}
	\begin{aligned}
		\cos^2(x)+\sin^2(x) = &\, \Re\left(e^{ix}\right)^2+\Im\left(e^{ix}\right)^2 \\
		= & \left(\frac{1}{2} \left(e^{ix}+\overline{e^{ix}}\right)\right)^2 + \left(\frac{i}{2} \left(e^{ix}-\overline{e^{ix}}\right)\right)^2 \\
		= & \left(\frac{1}{2}\right)^2 \left(e^{ix}+e^{-ix}\right)^2 + \left(\frac{i}{2}\right)^2 \left(e^{ix}-e^{-ix}\right)^2 \\
		= & \frac{1}{4} \left(e^{2ix}+e^{-2ix}+2e^{ix-ix}\right) - \frac{1}{4} \left(e^{2ix}+e^{-2ix}-2e^{ix-ix}\right) \\
		= & \frac{1}{4} \left( 2e^0+2e^0 \right) \\
		= & 1
		% z=z+y+x \Longrightarrow z=y+z+x \Longrightarrow z=y+x+z \Longrightarrow 0=y+x
	\end{aligned}
\end{equation}

However, it turned out that some parts are repeated over and over again.
% {Calculation (\ref{eq:tedios_calculation})} shows simple example where solving the equation $z=z+y+x$ with just the commutative rule $a+b=b+a$ and $a+b=c+b \Longleftarrow a=c$ seems needless long.
% Eliminating $z$ on both sides of the equation should be learned by the network as it is a recurring pattern in mathematical problems.
{Calculation (\ref{eq:tedios_calculation})} is an example calculation to simplify the trigonometric sum $\cos^2(x)+\sin^2(x)$, just using a basic rule set.
As this pattern occurs frequently in some mathematical domains, it might be useful to train such found rules into the network.   
These are exactly the corollaries that could be inserted into the original rule set.
To do this, you need to address three challenges:

\begin{enumerate}[label=(\roman*)]
	\item It should evaluate which corollary is worth to store.
	\item It should insert the new rule into the already trained network.
	\item Since there can be a large number of interesting corollaries, the training and inference time should increase less than linearly with the number of rules.
\end{enumerate}

One can overcome these challenges with a new network architecture, which will be presented in a future paper.

\subsubsection{Optimizing the Network}

As mentioned earlier, the limited time budget resulted in a far from perfect network architecture.
The same is true for the time-performance of the indexed CNN operation and which would allow hyper-parameter tuning to be performed in a feasible duration.

\subsubsection{Benchmarks with current data sets}

Hendrycks et al. claim that accuracy of current transformer based models remains relatively low \cite{hendrycks2021measuring}.
Fortunately they provide a benchmark dataset (MATH) with 12500 challenging competition mathematics problems.

Additional the log of manual calculation steps from the HOList dataset by Bansel et al. \cite{kaliszyk2017holstep} would be interesting for testing our approach.
Li et al. built a non-synthetic dataset from the largest repository of proofs written by human experts in a theorem prover \cite{li2021isarstep}.

\subsubsection{Training on proxy tasks}

It might be worth to investigate if a pre-training on a proxy task such as predicting missing node symbols $t_p$ in a term $T$ can help to build a better backbone.
This paradigm is applied by Rabe et al. \cite{rabe2020mathematical}.

\subsection{Far Future}

In university level mathematics many rules depend on multiple premises.
E.g. the simple commutative property has three: $\forall a \in \mathbb{R}$, and $\forall b \in \mathbb{R}$ applies $a\cdot b \Longrightarrow b\cdot a$.
This could be represented by the concatenation via $A_1 \wedge \cdots \wedge A_n \Longrightarrow B$.
Then you are almost at propositional logic with the challenge of multiple concurrent chains of computation required for the final result.
This requires an extension to the current core algorithm. For example meta rules as \textit{reductio ad absurdum}.

Moreover, some premises use first-order logic, which introduces the handling of complex mathematical sets.


\printbibliography
\end{document}
