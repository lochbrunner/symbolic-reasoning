@inproceedings{Lample2020Deep,
  title     = {Deep Learning For Symbolic Mathematics},
  author    = {Guillaume Lample and François Charton},
  booktitle = {International Conference on Learning Representations},
  year      = {2020},
  url       = {https://openreview.net/forum?id=S1eZYeHFDS}
}

@article{44806,
  title   = {Mastering the game of Go with deep neural networks and tree search},
  author  = {David Silver and Aja Huang and Christopher J. Maddison and Arthur Guez and Laurent Sifre and George van den Driessche and Julian Schrittwieser and Ioannis Antonoglou and Veda Panneershelvam and Marc Lanctot and Sander Dieleman and Dominik Grewe and John Nham and Nal Kalchbrenner and Ilya Sutskever and Timothy Lillicrap and Madeleine Leach and Koray Kavukcuoglu and Thore Graepel and Demis Hassabis},
  year    = {2016},
  url     = {http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html},
  journal = {Nature},
  pages   = {484--503},
  volume  = {529}
}

@article{graves2016hybrid,
  title     = {Hybrid computing using a neural network with dynamic external memory},
  author    = {Graves, Alex and Wayne, Greg and Reynolds, Malcolm and Harley, Tim and Danihelka, Ivo and Grabska-Barwi{\'n}ska, Agnieszka and Colmenarejo, Sergio G{\'o}mez and Grefenstette, Edward and Ramalho, Tiago and Agapiou, John and others},
  journal   = {Nature},
  volume    = {538},
  number    = {7626},
  pages     = {471--476},
  year      = {2016},
  publisher = {Nature Publishing Group}
}

@article{tai2015improved,
  title   = {Improved semantic representations from tree-structured long short-term memory networks},
  author  = {Tai, Kai Sheng and Socher, Richard and Manning, Christopher D},
  journal = {arXiv preprint arXiv:1503.00075},
  year    = {2015}
}

@article{vaswani2017attention,
  title   = {Attention is all you need},
  author  = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
  journal = {arXiv preprint arXiv:1706.03762},
  year    = {2017}
}

@inproceedings{gehring2017convolutional,
  title        = {Convolutional sequence to sequence learning},
  author       = {Gehring, Jonas and Auli, Michael and Grangier, David and Yarats, Denis and Dauphin, Yann N},
  booktitle    = {International Conference on Machine Learning},
  pages        = {1243--1252},
  year         = {2017},
  organization = {PMLR}
}

@article{10.7717/peerj-cs.103,
  title    = {SymPy: symbolic computing in Python},
  author   = {Meurer, Aaron and Smith, Christopher P. and Paprocki, Mateusz and \v{C}ert\'{i}k, Ond\v{r}ej and Kirpichev, Sergey B. and Rocklin, Matthew and Kumar, Amit and Ivanov, Sergiu and Moore, Jason K. and Singh, Sartaj and Rathnayake, Thilina and Vig, Sean and Granger, Brian E. and Muller, Richard P. and Bonazzi, Francesco and Gupta, Harsh and Vats, Shivam and Johansson, Fredrik and Pedregosa, Fabian and Curry, Matthew J. and Terrel, Andy R. and Rou\v{c}ka, \v{S}t\v{e}p\'{a}n and Saboo, Ashutosh and Fernando, Isuru and Kulal, Sumith and Cimrman, Robert and Scopatz, Anthony},
  year     = 2017,
  month    = Jan,
  keywords = {Python, Computer algebra system, Symbolics},
  abstract = {
            SymPy is an open-source computer algebra system written in pure Python. It is built with a focus on extensibility and ease of use, through both interactive and programmatic applications. These characteristics have led SymPy to become a popular symbolic library for the scientific Python ecosystem. This paper presents the architecture of SymPy, a description of its features, and a discussion of select submodules. The supplementary material provides additional examples and further outlines details of the architecture and features of SymPy.
         },
  volume   = 3,
  pages    = {e103},
  journal  = {PeerJ Computer Science},
  issn     = {2376-5992},
  url      = {https://doi.org/10.7717/peerj-cs.103},
  doi      = {10.7717/peerj-cs.103}
}

@online{wolfram,
  author = {Wolfram Research},
  title  = {The Internals of the Wolfram System},
  date   = {2021-03},
  url    = {https://reference.wolfram.com/language/tutorial/TheInternalsOfTheWolframSystem.html}
}

@misc{lamb2020graph,
  title         = {Graph Neural Networks Meet Neural-Symbolic Computing: A Survey and Perspective},
  author        = {Luis C. Lamb and Artur Garcez and Marco Gori and Marcelo Prates and Pedro Avelar and Moshe Vardi},
  year          = {2020},
  eprint        = {2003.00330},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI}
}

% used
@misc{davis2019use,
  title         = {The Use of Deep Learning for Symbolic Integration: A Review of (Lample and Charton, 2019)},
  author        = {Ernest Davis},
  year          = {2019},
  eprint        = {1912.05752},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

% used
@misc{hahn2021teaching,
  title         = {Teaching Temporal Logics to Neural Networks},
  author        = {Christopher Hahn and Frederik Schmitt and Jens U. Kreber and Markus N. Rabe and Bernd Finkbeiner},
  year          = {2021},
  eprint        = {2003.04218},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LO}
}

% Datasets
@misc{hendrycks2021measuring,
  title         = {Measuring Mathematical Problem Solving With the MATH Dataset},
  author        = {Dan Hendrycks and Collin Burns and Saurav Kadavath and Akul Arora and Steven Basart and Eric Tang and Dawn Song and Jacob Steinhardt},
  year          = {2021},
  eprint        = {2103.03874},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@misc{kaliszyk2017holstep,
  title         = {HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving},
  author        = {Cezary Kaliszyk and François Chollet and Christian Szegedy},
  year          = {2017},
  eprint        = {1703.00426},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI}
}

@misc{li2021isarstep,
  title         = {IsarStep: a Benchmark for High-level Mathematical Reasoning},
  author        = {Wenda Li and Lei Yu and Yuhuai Wu and Lawrence C. Paulson},
  year          = {2021},
  eprint        = {2006.09265},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LO}
}

@misc{kaliszyk2017holstep,
  title         = {HolStep: A Machine Learning Dataset for Higher-order Logic Theorem Proving},
  author        = {Cezary Kaliszyk and François Chollet and Christian Szegedy},
  year          = {2017},
  eprint        = {1703.00426},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI}
}

% TODO: newer submittion
@misc{charton2021learning,
  title         = {Learning advanced mathematical computations from examples},
  author        = {François Charton and Amaury Hayat and Guillaume Lample},
  year          = {2021},
  eprint        = {2006.06462},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

% Not that interesting...
@misc{mistry2021primer,
  title         = {A Primer for Neural Arithmetic Logic Modules},
  author        = {Bhumika Mistry and Katayoun Farrahi and Jonathon Hare},
  year          = {2021},
  eprint        = {2101.09530},
  archiveprefix = {arXiv},
  primaryclass  = {cs.NE}
}

% TODO
% https://arxiv.org/pdf/2003.00330.pdf
% https://arxiv.org/abs/2011.02415
% https://arxiv.org/pdf/2006.04757.pdf  Mathematical Reasoning via Self-supervisedSkip-tree Training
% https://arxiv.org/abs/2006.09265 IsarStep: a Benchmark for High-level Mathematical Reasoning
% https://arxiv.org/abs/2102.05547 Learning Equational Theorem Proving
% https://arxiv.org/abs/2011.06673 Symbolically Solving Partial Differential Equations using Deep Learning
% https://arxiv.org/abs/2012.08508 Object-based attention for spatio-temporal reasoning: Outperforming neuro-symbolic models with flexible distributed architectures

@misc{marcus2020decade,
  title         = {The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence},
  author        = {Gary Marcus},
  year          = {2020},
  eprint        = {2002.06177},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI}
}

@misc{panju2020neurosymbolic,
  title         = {A Neuro-Symbolic Method for Solving Differential and Functional Equations},
  author        = {Maysum Panju and Ali Ghodsi},
  year          = {2020},
  eprint        = {2011.02415},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@article{rabe2020mathematical,
  title   = {Mathematical reasoning via self-supervised skip-tree training},
  author  = {Rabe, Markus N and Lee, Dennis and Bansal, Kshitij and Szegedy, Christian},
  journal = {arXiv preprint arXiv:2006.04757},
  year    = {2020}
}

% naive approach
@misc{piepenbrock2021learning,
  title         = {Learning Equational Theorem Proving},
  author        = {Jelle Piepenbrock and Tom Heskes and Mikoláš Janota and Josef Urban},
  year          = {2021},
  eprint        = {2102.05547},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

% Deep Mind. Not used yet
@misc{ding2020objectbased,
  title         = {Object-based attention for spatio-temporal reasoning: Outperforming neuro-symbolic models with flexible distributed architectures},
  author        = {David Ding and Felix Hill and Adam Santoro and Matt Botvinick},
  year          = {2020},
  eprint        = {2012.08508},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}
